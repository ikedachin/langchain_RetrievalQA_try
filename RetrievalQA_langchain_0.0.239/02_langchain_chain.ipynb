{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import openai\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import CharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../api.yaml', 'r') as f:\n",
    "    api = yaml.safe_load(f)\n",
    "openai.api_key = api['openai']\n",
    "os.environ['OPENAI_API_KEY'] = api['openai']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./text_files_rag/hiraya_whisper_large.txt', 'r') as f:\n",
    "with open('../text_files/softbank_world_2023_whisper_large.txt', 'r') as f:\n",
    "    text_all = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# チャンクの分割\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator='\\n', # セパレート文字\n",
    "    chunk_size=300, # チャンクのサイズ\n",
    "    chunk_overlap=20, # オーバーラップの最大文字数\n",
    ")\n",
    "texts = text_splitter.split_text(text_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "皆さんおはようござい : 279\n",
      "最も大切なページの一 : 293\n",
      "知能の強さには2つの : 279\n",
      "じゃあAIの強さとは : 277\n",
      "一つはアルゴリズムの : 296\n",
      "あら?\n",
      "やばい\n",
      "AG : 294\n",
      "この\n",
      "3文字の頭文字 : 288\n",
      "ほぼ全部の分野で\n",
      "抜 : 300\n",
      "まだ知恵の方が上だと : 296\n",
      "AGIの定義は\n",
      "人類 : 300\n",
      "仕事ってなんだと\n",
      "会 : 291\n",
      "それは僕の勝手な思い : 289\n",
      "自分は一体どういう考 : 294\n",
      "遅れてしまっているか : 290\n",
      "自動車もぶつかって事 : 287\n",
      "電気がどれほど有益で : 295\n",
      "いくつか何回かこうや : 284\n",
      "どのくらい優れている : 299\n",
      "そこまでできるんです : 293\n",
      "つまりもう疑問の余地 : 297\n",
      "人類が生まれて\n",
      "20 : 297\n",
      "10年以内にですね\n",
      " : 281\n",
      "GPTのですね\n",
      "つい : 298\n",
      "どこをどういじくれば : 292\n",
      "いろんな会社が画像だ : 281\n",
      "この生成AIはプログ : 294\n",
      "自分で学習していくわ : 291\n",
      "より重要なデータです : 296\n",
      "例明記にですね\n",
      "我々 : 297\n",
      "世界の時価総額の\n",
      "ト : 300\n",
      "それに真正面から取り : 297\n",
      "みんな広告を争ってい : 296\n",
      "20年後に\n",
      "一気に人 : 291\n",
      "交通機関\n",
      "モビリティ : 291\n",
      "なんか無理やりこう\n",
      " : 291\n",
      "コールセンターにおけ : 294\n",
      "サポートするというの : 297\n",
      "一言言えば\n",
      "I wi : 296\n",
      "遺伝子の解析によって : 300\n",
      "つまり\n",
      "好む好まない : 300\n",
      "こういうような規制が : 291\n",
      "一方\n",
      "今日現在の\n",
      "企 : 300\n",
      "拒否するか\n",
      "積極的に : 299\n",
      "僕はソフトバンクを世 : 293\n",
      "縦横斜めに\n",
      "我々グル : 296\n",
      "社員証はゼロです\n",
      "す : 299\n",
      "我々は\n",
      "生成AI活用 : 297\n",
      "おにぎり10個くらい : 291\n",
      "僕の個人の\n",
      "内に秘め : 300\n",
      "戦略も今\n",
      "打ち合わせ : 298\n",
      "いうのがソフトバンク : 300\n",
      "大きなLLMと\n",
      "それ : 291\n",
      "なんだチャットだろ\n",
      " : 297\n",
      "このページ\n",
      "AGIが : 299\n",
      "10倍の次は1万倍だ : 299\n",
      "その知能が\n",
      "何倍ぐら : 293\n",
      "つまり1万倍の差があ : 295\n",
      "考える時が来たと\n",
      "人 : 300\n",
      "今会場で朝ですね\n",
      "今 : 293\n",
      "強い願望を持っている : 294\n",
      "なんで使ってないんだ : 290\n",
      "目覚めよと\n",
      "日本のた : 294\n",
      "ちょっとARM\n",
      "今日 : 288\n",
      "クラウドのようなマー : 297\n",
      "アーキテクチャの一つ : 291\n",
      "このテクノロジーを使 : 298\n",
      "簡単にプログラムでき : 286\n",
      "持って使われているわ : 294\n",
      "やはり\n",
      "自動車のソリ : 299\n",
      "アクセレレーターGP : 282\n",
      "そしてAIとなります : 296\n",
      "この問題の解決の仕方 : 294\n",
      "それでは\n",
      "孫さんと私 : 289\n",
      "これは消費電力\n",
      "そし : 286\n",
      "ケーブルニッチで創設 : 298\n",
      "取り組んできたわけな : 287\n",
      "それが何かというと\n",
      " : 300\n",
      "オプティマイズをして : 281\n",
      "だからこそARMを買 : 288\n",
      "資料分析\n",
      "そういった : 300\n",
      "変革がある\n",
      "というこ : 295\n",
      "使われることになるで : 292\n",
      "人間の仕事がなくなる : 292\n",
      "1点\n",
      "挙げるのであれ : 292\n",
      "昨年\n",
      "自分自身も\n",
      "子 : 284\n",
      "そしてAGIの\n",
      "コラ : 292\n",
      "AGIが介入し\n",
      "こん : 298\n",
      "やはり人々にとって\n",
      " : 296\n",
      "そして新たな\n",
      "エキサ : 250\n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    print(text[:10], ':', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- セパレータ（デフォルトは'\\n\\n'）でテキストを小さなチャンクに分割\n",
    "- 小さなチャンクを特定文字数になるまでマージし、大きなチャンクを作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ベクトルデーターベースの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI, OpenAIChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベクトルデータベースの作成\n",
    "docsearch = FAISS.from_texts(\n",
    "    embedding=OpenAIEmbeddings(), # 埋め込みモデル\n",
    "    texts=texts # チャンク\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ikedashinji/Desktop/corporate _collabo/langchain_239_env/lib/python3.10/site-packages/langchain/llms/openai.py:750: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 質疑応答チェーンの作成\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAIChat(model='gpt-4-1106-preview', temperature=0), # LLM\n",
    "    # llm=OpenAI(model='gpt-4-1106-preview', temperature=0), # LLM\n",
    "    # chain_type='stuff', # チェーンタイプ\n",
    "    chain_type='refine', # チェーンタイプ\n",
    "    # chain_type='map_reduce', # チェーンタイプ\n",
    "    # chain_type='map_rerank', # チェーンタイプ\n",
    "    retriever=docsearch.as_retriever(), # リトリバー\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新しいコンテキストを考慮に入れた上で、孫さんはAGI（人工汎用知能）が「10年以内に実現する」と述べており、AGIを使う人と使わない人の差は「人間対猿ぐらいの差ができる」とも指摘しています。この発言は、AGIの社会的影響の大きさを強調しているものであり、具体的な年数については「10年以内」という期間を示唆していますが、それ以上の詳細な年を明言しているわけではありません。したがって、元の回答に追加情報を加えて、以下のように答えることができます。\n",
      "\n",
      "孫さんはAGIが「10年以内に実現する」と述べており、その社会的影響はAGIを使う人と使わない人の間で「人間対猿ぐらいの差ができる」と考えていますが、具体的な年を言っているわけではありません。\n"
     ]
    }
   ],
   "source": [
    "print(qa_chain.run('孫さんは何年にAGIができると言っていますか？日本語で答えてください。'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新しいコンテキストを踏まえて、お答えを修正いたします。\n",
      "\n",
      "「ASI」とは「Artificial Superintelligence」の略で、「人工超知能」を意味します。これは、人間の知能をはるかに超える能力を持つ理論上のAIのことを指しています。一方で、コンテキストに出てきた「AGI」は「Artificial General Intelligence」、つまり「人工汎用知能」を意味し、あらゆる知的タスクで人間と同等に機能するAIを指します。現在のところは実現していない理論上の概念ですが、将来的にはAIが人間の知能を全ての分野で超える可能性があり、その時点で「人工超知能」、すなわちASIが現れることになります。\n",
      "\n",
      "コンテキストによると、一般の人々の間では「AGI」についての認識がまだ低いようですが、その重要性を理解することは非常に価値があるとされています。AGIの実現は、人類の進化において大きな転換点となる可能性があり、それに続くASIの出現はさらに大きな影響をもたらすことでしょう。\n",
      "\n",
      "したがって、お尋ねの「ASI」は「人工超知能」を指し、将来的には全ての分野で人間の知能を超えるAIという意味合いがあります。そして、現在議論されている「人工汎用知能」AGIの理解とその重要性を知ることは、我々にとって非常に重要であると言えるでしょう。\n"
     ]
    }
   ],
   "source": [
    "print(qa_chain.run('ASIとはなんですか？日本語で答えてください。'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'新しいコンテキストを考慮に入れた上で、元の回答を修正する必要があります。孫さんは、生成AIを使ったことがない人に対して、AIの可能性について語っているようです。彼はAIが特定の分野で人間の能力を超えていることを認めつつも、まだ全ての分野で人間を超えるには至っていないと述べています。そして、AIに限界があるという意見に対して、それはAIの限界ではなく、人々の理解に限界があると反論しています。彼は、将来的にAIがほぼ全ての分野で人間の知識を超えると信じていることを示唆しています。\\n\\nこのコンテキストに基づいて、孫さんが生成AIを使ったことがない人に言っていることは、AIの現在の能力と将来の可能性についての彼の見解であり、特に生成AIの活用コンテストについて言及しているわけではないようです。したがって、元の回答はこの新しいコンテキストには適していないため、以下のように修正します。\\n\\n孫さんは、生成AIを使ったことがない人に対して、AIが特定の分野では既に人間の能力を超えているが、全ての分野でそれが実現しているわけではないと説明しています。そして、AIに限界があるという意見に対しては、それはAIの限界ではなく、人々の理解に限界があると指摘しています。彼はAIの将来的な発展に楽観的であり、いずれAIがほぼ全ての分野で人間の知識を超えると考えているようです。'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.run('孫さんは生成AIを使ったことがない人になんと言っていますか？日本語で教えてください。')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieverのchainタイプの種類\n",
    "- stuff  \n",
    "すべてのデータをモデルに渡す。長文は機能しない。呼び出しは一回だけで済むので早い\n",
    "- map_reduce  \n",
    "チャンク毎にプロンプトを生成してLLMを呼び出す。大きなデータが使える。最後の結合時に一部の情報が失われてしまう。\n",
    "- refine  \n",
    "チャンク毎にプロンプトを生成するが、前のチャンクの出力と合わせてLLMを呼び出す。シーケンシャルな処理\n",
    "- map_rerank  \n",
    "チャンク毎にプロンプトを作ってLLMを呼び、応答をランク付けする。このスコアに基づいて応答する。ドキュメント間で情報が共有できない。一つの単純んな答えがあるときに最適。\n",
    "\n",
    "  \n",
    "### retrieverとは\n",
    "コンピュータ用語では特定のキーワードや条件に基づいて、情報を収集してユーバーに情報を提供するシステムを表す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
